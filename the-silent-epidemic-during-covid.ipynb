{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7480703,"sourceType":"datasetVersion","datasetId":4354672}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sbhatti34/the-silent-epidemic-during-covid?scriptVersionId=247544273\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib\nimport seaborn as sns\nplt.style.use('seaborn-v0_8-muted')\nfrom IPython.display import display\nfrom scipy import stats\n\n\n%pip install missingno\nfrom IPython.display import clear_output\nimport missingno as msno\n\nfrom scipy.stats import ttest_ind\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\n\nfrom IPython.display import display\nimport matplotlib.ticker as ticker\n\nclear_output()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:03:52.549214Z","iopub.execute_input":"2025-06-26T19:03:52.549952Z","iopub.status.idle":"2025-06-26T19:04:02.467447Z","shell.execute_reply.started":"2025-06-26T19:03:52.549882Z","shell.execute_reply":"2025-06-26T19:04:02.466569Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/mental-health-care-in-the-last-4-weeks/Mental Health Care in the Last 4 Weeks.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.469152Z","iopub.execute_input":"2025-06-26T19:04:02.469715Z","iopub.status.idle":"2025-06-26T19:04:02.545334Z","shell.execute_reply.started":"2025-06-26T19:04:02.469686Z","shell.execute_reply":"2025-06-26T19:04:02.544406Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Basic understanding of the dataset","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.546588Z","iopub.execute_input":"2025-06-26T19:04:02.546972Z","iopub.status.idle":"2025-06-26T19:04:02.554009Z","shell.execute_reply.started":"2025-06-26T19:04:02.546937Z","shell.execute_reply":"2025-06-26T19:04:02.553138Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(10404, 13)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.554996Z","iopub.execute_input":"2025-06-26T19:04:02.555316Z","iopub.status.idle":"2025-06-26T19:04:02.599363Z","shell.execute_reply.started":"2025-06-26T19:04:02.555294Z","shell.execute_reply":"2025-06-26T19:04:02.598478Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"               Group          State       Subgroup Phase  Time Period  \\\n0  National Estimate  United States  United States     2           13   \n1             By Age  United States  18 - 29 years     2           13   \n2             By Age  United States  30 - 39 years     2           13   \n3             By Age  United States  40 - 49 years     2           13   \n4             By Age  United States  50 - 59 years     2           13   \n\n       Time Period Label Time Period Start Date Time Period End Date  Value  \\\n0  Aug 19 - Aug 31, 2020             08/19/2020           08/31/2020   19.4   \n1  Aug 19 - Aug 31, 2020             08/19/2020           08/31/2020   18.7   \n2  Aug 19 - Aug 31, 2020             08/19/2020           08/31/2020   18.3   \n3  Aug 19 - Aug 31, 2020             08/19/2020           08/31/2020   20.4   \n4  Aug 19 - Aug 31, 2020             08/19/2020           08/31/2020   21.2   \n\n   LowCI  HighCI Confidence Interval Quartile Range  \n0   19.0    19.8         19.0 - 19.8            NaN  \n1   17.2    20.3         17.2 - 20.3            NaN  \n2   17.3    19.2         17.3 - 19.2            NaN  \n3   19.5    21.3         19.5 - 21.3            NaN  \n4   20.2    22.2         20.2 - 22.2            NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Group</th>\n      <th>State</th>\n      <th>Subgroup</th>\n      <th>Phase</th>\n      <th>Time Period</th>\n      <th>Time Period Label</th>\n      <th>Time Period Start Date</th>\n      <th>Time Period End Date</th>\n      <th>Value</th>\n      <th>LowCI</th>\n      <th>HighCI</th>\n      <th>Confidence Interval</th>\n      <th>Quartile Range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>National Estimate</td>\n      <td>United States</td>\n      <td>United States</td>\n      <td>2</td>\n      <td>13</td>\n      <td>Aug 19 - Aug 31, 2020</td>\n      <td>08/19/2020</td>\n      <td>08/31/2020</td>\n      <td>19.4</td>\n      <td>19.0</td>\n      <td>19.8</td>\n      <td>19.0 - 19.8</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>By Age</td>\n      <td>United States</td>\n      <td>18 - 29 years</td>\n      <td>2</td>\n      <td>13</td>\n      <td>Aug 19 - Aug 31, 2020</td>\n      <td>08/19/2020</td>\n      <td>08/31/2020</td>\n      <td>18.7</td>\n      <td>17.2</td>\n      <td>20.3</td>\n      <td>17.2 - 20.3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>By Age</td>\n      <td>United States</td>\n      <td>30 - 39 years</td>\n      <td>2</td>\n      <td>13</td>\n      <td>Aug 19 - Aug 31, 2020</td>\n      <td>08/19/2020</td>\n      <td>08/31/2020</td>\n      <td>18.3</td>\n      <td>17.3</td>\n      <td>19.2</td>\n      <td>17.3 - 19.2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>By Age</td>\n      <td>United States</td>\n      <td>40 - 49 years</td>\n      <td>2</td>\n      <td>13</td>\n      <td>Aug 19 - Aug 31, 2020</td>\n      <td>08/19/2020</td>\n      <td>08/31/2020</td>\n      <td>20.4</td>\n      <td>19.5</td>\n      <td>21.3</td>\n      <td>19.5 - 21.3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>By Age</td>\n      <td>United States</td>\n      <td>50 - 59 years</td>\n      <td>2</td>\n      <td>13</td>\n      <td>Aug 19 - Aug 31, 2020</td>\n      <td>08/19/2020</td>\n      <td>08/31/2020</td>\n      <td>21.2</td>\n      <td>20.2</td>\n      <td>22.2</td>\n      <td>20.2 - 22.2</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df.info()\nprint()\ndf.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.601511Z","iopub.execute_input":"2025-06-26T19:04:02.601774Z","iopub.status.idle":"2025-06-26T19:04:02.656628Z","shell.execute_reply.started":"2025-06-26T19:04:02.601753Z","shell.execute_reply":"2025-06-26T19:04:02.655715Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10404 entries, 0 to 10403\nData columns (total 13 columns):\n #   Column                  Non-Null Count  Dtype  \n---  ------                  --------------  -----  \n 0   Group                   10404 non-null  object \n 1   State                   10404 non-null  object \n 2   Subgroup                10404 non-null  object \n 3   Phase                   10404 non-null  object \n 4   Time Period             10404 non-null  int64  \n 5   Time Period Label       10404 non-null  object \n 6   Time Period Start Date  10404 non-null  object \n 7   Time Period End Date    10404 non-null  object \n 8   Value                   9914 non-null   float64\n 9   LowCI                   9914 non-null   float64\n 10  HighCI                  9914 non-null   float64\n 11  Confidence Interval     9914 non-null   object \n 12  Quartile Range          6732 non-null   object \ndtypes: float64(3), int64(1), object(9)\nmemory usage: 1.0+ MB\n\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        Time Period        Value        LowCI       HighCI\ncount  10404.000000  9914.000000  9914.000000  9914.000000\nmean      28.134948    17.450736    14.771565    20.475661\nstd       11.040210     8.270565     7.659396     9.052521\nmin        1.000000     1.400000     0.800000     2.000000\n25%       20.000000    10.300000     8.000000    12.900000\n50%       29.000000    16.200000    13.900000    19.200000\n75%       37.000000    24.000000    20.800000    27.400000\nmax       45.000000    62.900000    53.200000    71.900000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time Period</th>\n      <th>Value</th>\n      <th>LowCI</th>\n      <th>HighCI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10404.000000</td>\n      <td>9914.000000</td>\n      <td>9914.000000</td>\n      <td>9914.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>28.134948</td>\n      <td>17.450736</td>\n      <td>14.771565</td>\n      <td>20.475661</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>11.040210</td>\n      <td>8.270565</td>\n      <td>7.659396</td>\n      <td>9.052521</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.400000</td>\n      <td>0.800000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>20.000000</td>\n      <td>10.300000</td>\n      <td>8.000000</td>\n      <td>12.900000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>29.000000</td>\n      <td>16.200000</td>\n      <td>13.900000</td>\n      <td>19.200000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>37.000000</td>\n      <td>24.000000</td>\n      <td>20.800000</td>\n      <td>27.400000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>45.000000</td>\n      <td>62.900000</td>\n      <td>53.200000</td>\n      <td>71.900000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"<p><b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# look at the unique values for categorical columns</b>","metadata":{}},{"cell_type":"code","source":"# View all unique values in the categorical columns\n\ncategorical_columns = df.select_dtypes(include=['object']).columns\nfor column in categorical_columns:\n    unique_values = df[column].unique()\n    print(f\"Unique values in '{column}':\")\n    print(unique_values)\n    print()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.65745Z","iopub.execute_input":"2025-06-26T19:04:02.657771Z","iopub.status.idle":"2025-06-26T19:04:02.673549Z","shell.execute_reply.started":"2025-06-26T19:04:02.657669Z","shell.execute_reply":"2025-06-26T19:04:02.672521Z"}},"outputs":[{"name":"stdout","text":"Unique values in 'Group':\n['National Estimate' 'By Age' 'By Sex'\n 'By Presence of Symptoms of Anxiety/Depression'\n 'By Race/Hispanic ethnicity' 'By Education' 'By State'\n 'By Disability status' 'By Gender identity' 'By Sexual orientation']\n\nUnique values in 'State':\n['United States' 'Alabama' 'Alaska' 'Arizona' 'Arkansas' 'California'\n 'Colorado' 'Connecticut' 'Delaware' 'District of Columbia' 'Florida'\n 'Georgia' 'Hawaii' 'Idaho' 'Illinois' 'Indiana' 'Iowa' 'Kansas'\n 'Kentucky' 'Louisiana' 'Maine' 'Maryland' 'Massachusetts' 'Michigan'\n 'Minnesota' 'Mississippi' 'Missouri' 'Montana' 'Nebraska' 'Nevada'\n 'New Hampshire' 'New Jersey' 'New Mexico' 'New York' 'North Carolina'\n 'North Dakota' 'Ohio' 'Oklahoma' 'Oregon' 'Pennsylvania' 'Rhode Island'\n 'South Carolina' 'South Dakota' 'Tennessee' 'Texas' 'Utah' 'Vermont'\n 'Virginia' 'Washington' 'West Virginia' 'Wisconsin' 'Wyoming']\n\nUnique values in 'Subgroup':\n['United States' '18 - 29 years' '30 - 39 years' '40 - 49 years'\n '50 - 59 years' '60 - 69 years' '70 - 79 years' '80 years and above'\n 'Male' 'Female'\n 'Did not experience symptoms of anxiety/depression in the past 4 weeks'\n 'Experienced symptoms of anxiety/depression in past 4 weeks'\n 'Hispanic or Latino' 'Non-Hispanic White, single race'\n 'Non-Hispanic Black, single race' 'Non-Hispanic Asian, single race'\n 'Non-Hispanic, other races and multiple races'\n 'Less than a high school diploma' 'High school diploma or GED'\n \"Some college/Associate's degree\" \"Bachelor's degree or higher\" 'Alabama'\n 'Alaska' 'Arizona' 'Arkansas' 'California' 'Colorado' 'Connecticut'\n 'Delaware' 'District of Columbia' 'Florida' 'Georgia' 'Hawaii' 'Idaho'\n 'Illinois' 'Indiana' 'Iowa' 'Kansas' 'Kentucky' 'Louisiana' 'Maine'\n 'Maryland' 'Massachusetts' 'Michigan' 'Minnesota' 'Mississippi'\n 'Missouri' 'Montana' 'Nebraska' 'Nevada' 'New Hampshire' 'New Jersey'\n 'New Mexico' 'New York' 'North Carolina' 'North Dakota' 'Ohio' 'Oklahoma'\n 'Oregon' 'Pennsylvania' 'Rhode Island' 'South Carolina' 'South Dakota'\n 'Tennessee' 'Texas' 'Utah' 'Vermont' 'Virginia' 'Washington'\n 'West Virginia' 'Wisconsin' 'Wyoming' 'With disability'\n 'Without disability' 'Cis-gender male' 'Cis-gender female' 'Transgender'\n 'Gay or lesbian' 'Straight' 'Bisexual']\n\nUnique values in 'Phase':\n['2' '3 (Oct 28 – Dec 21)' '-1' '3 (Jan 6 – Mar 29)' '3.1' '3.2' '3.3'\n '3.4']\n\nUnique values in 'Time Period Label':\n['Aug 19 - Aug 31, 2020' 'Sep 2 - Sep 14, 2020' 'Sep 16 - Sep 28, 2020'\n 'Sep 30 - Oct 12, 2020' 'Oct 14 - Oct 26, 2020' 'Oct 28 - Nov 9, 2020'\n 'Nov 11 - Nov 23, 2020' 'Nov 25 - Dec 7, 2020' 'Dec 9 - Dec 21, 2020'\n 'Dec 22, 2020 - Jan 5, 2021' 'Jan 6 - Jan 18, 2021'\n 'Jan 20 - Feb 1, 2021' 'Feb 3 - Feb 15, 2021' 'Feb 17 - Mar 1, 2021'\n 'Mar 3 - Mar 15, 2021' 'Mar 17 - Mar 29, 2021' 'Mar 30 - Apr 13, 2021'\n 'Apr 14 - Apr 26, 2021' 'Apr 28 - May 10, 2021' 'May 12 - May 24, 2021'\n 'May 26 - Jun 7, 2021' 'Jun 9 - Jun 21, 2021' 'Jun 23 - Jul 5, 2021'\n 'Jul 6 - Jul 20, 2021' 'Jul 21 - Aug 2, 2021' 'Aug 4 - Aug 16, 2021'\n 'Aug 18 - Aug 30, 2021' 'Sep 1 - Sep 13, 2021' 'Sep 15 - Sep 27, 2021'\n 'Sep 29 - Oct 11, 2021' 'Oct 12 - Nov 30, 2021' 'Dec 1 - Dec 13, 2021'\n 'Dec 29, 2021 - Jan 10, 2022' 'Jan 26 - Feb 7, 2022'\n 'Feb 23 - Mar 1, 2022' 'Mar 2 - Mar 14, 2022' 'Mar 30 - Apr 11, 2022'\n 'Apr 27 - May 9, 2022']\n\nUnique values in 'Time Period Start Date':\n['08/19/2020' '09/02/2020' '09/16/2020' '09/30/2020' '10/14/2020'\n '10/28/2020' '11/11/2020' '11/25/2020' '12/09/2020' '12/22/2020'\n '01/06/2021' '01/20/2021' '02/03/2021' '02/17/2021' '03/03/2021'\n '03/17/2021' '03/30/2021' '04/14/2021' '04/28/2021' '05/12/2021'\n '05/26/2021' '06/09/2021' '06/23/2021' '07/06/2021' '07/21/2021'\n '08/04/2021' '08/18/2021' '09/01/2021' '09/15/2021' '09/29/2021'\n '10/12/2021' '12/01/2021' '12/29/2021' '01/26/2022' '02/23/2022'\n '03/02/2022' '03/30/2022' '04/27/2022']\n\nUnique values in 'Time Period End Date':\n['08/31/2020' '09/14/2020' '09/28/2020' '10/12/2020' '10/26/2020'\n '11/09/2020' '11/23/2020' '12/07/2020' '12/21/2020' '01/05/2021'\n '01/18/2021' '02/01/2021' '02/15/2021' '03/01/2021' '03/15/2021'\n '03/29/2021' '04/13/2021' '04/26/2021' '05/10/2021' '05/24/2021'\n '06/07/2021' '06/21/2021' '07/05/2021' '07/20/2021' '08/02/2021'\n '08/16/2021' '08/30/2021' '09/13/2021' '09/27/2021' '10/11/2021'\n '11/30/2021' '12/13/2021' '01/10/2022' '02/07/2022' '03/01/2022'\n '03/14/2022' '04/11/2022' '05/09/2022']\n\nUnique values in 'Confidence Interval':\n['19.0 - 19.8' '17.2 - 20.3' '17.3 - 19.2' ... '9.2 - 14.2' '8.2 - 16.5'\n '6.6 - 13.8']\n\nUnique values in 'Quartile Range':\n[nan '20.6-22.5' '12.2-18.4' '22.6-26.8' '18.5-20.5' '7.2-8.7' '4.9-7.1'\n '8.8-10.0' '10.1-19.1' '23.6-25.3' '17.7-21.7' '21.8-23.5' '25.4-28.4'\n '7.8-9.1' '9.2-10.1' '5.7-7.7' '10.2-12.9' '18.9-21.2' '11.2-18.8'\n '22.9-30.1' '21.3-22.8' '5.3-7.7' '7.8-8.9' '10.0-17.0' '9.0-9.9'\n '22.3-24.2' '13.3-22.2' '25.7-33.0' '24.3-25.6' '9.5-10.7' '10.8-13.1'\n '8.7-9.4' '6.5-8.6' '23.0-25.9' '19.2-21.3' '21.4-22.9' '5.1-7.7'\n '8.6-10.1' '7.8-8.5' '10.2-15.7' '26.0-29.1' '13.3-22.1' '22.2-23.7'\n '23.8-25.9' '11.2-15.1' '9.8-11.1' '8.7-9.7' '6.0-8.6' '22.5-32.1'\n '13.0-19.0' '19.1-20.3' '20.4-22.4' '4.6-7.6' '8.9-10.4' '10.5-14.8'\n '7.7-8.8' '25.4-33.5' '16.6-21.8' '21.9-23.1' '23.2-25.3' '9.8-10.8'\n '10.9-12.9' '8.5-9.7' '6.2-8.4' '21.2-24.1' '10.0-19.1' '19.2-21.1'\n '24.2-27.2' '6.1-8.0' '9.3-10.9' '8.1-9.2' '11.0-18.5' '22.4-24.8'\n '13.3-22.3' '27.1-30.4' '24.9-27.0' '4.9-9.3' '10.1-11.9' '12.0-14.1'\n '9.4-10.0' '23.9-27.6' '13.7-19.7' '21.8-23.8' '19.8-21.7' '9.0-9.7'\n '11.3-20.3' '5.6-8.9' '9.8-11.2' '27.1-33.2' '23.4-25.2' '17.6-23.3'\n '25.3-27.0' '6.7-9.2' '11.1-12.6' '9.3-11.0' '12.7-16.9' '25.1-31.4'\n '13.2-20.1' '20.2-22.1' '22.2-25.0' '6.1-8.5' '9.7-10.8' '8.6-9.6'\n '10.9-15.2' '28.5-33.6' '15.1-23.7' '26.0-28.4' '12.2-15.5' '10.9-12.1'\n '6.5-9.6' '23.4-25.0' '13.2-20.2' '25.1-33.0' '20.3-23.3' '4.4-8.4'\n '10.1-11.4' '11.5-15.8' '8.5-10.0' '26.3-28.2' '15.3-23.7' '28.3-34.8'\n '23.8-26.2' '10.1-11.6' '11.7-12.9' '13.0-18.5' '4.1-10.0' '23.2-25.5'\n '12.5-20.1' '25.6-34.2' '20.2-23.1' '8.6-9.7' '9.8-11.6' '4.1-8.5'\n '11.7-17.2' '26.8-28.7' '16.7-24.0' '24.1-26.7' '28.8-36.3' '12.8-13.6'\n '13.7-16.5' '10.4-12.7' '6.1-10.3' '22.0-24.5' '15.1-20.0' '24.6-28.5'\n '20.1-21.9' '5.0-8.4' '9.6-10.9' '11.0-16.9' '8.5-9.5' '22.9-25.5'\n '18.4-22.8' '25.6-27.4' '27.5-32.1' '12.6-17.3' '11.1-12.5' '7.3-10.1'\n '10.2-11.0' '23.1-24.9' '11.2-20.4' '20.5-23.0' '25.0-29.2' '8.7-9.9'\n '10.0-11.2' '4.8-8.6' '11.3-17.2' '26.2-28.5' '15.4-24.0' '24.1-26.1'\n '28.6-31.9' '11.3-12.6' '5.9-9.7' '12.7-16.1' '12.1-19.4' '24.7-31.8'\n '19.5-22.8' '22.9-24.6' '6.2-8.1' '8.2-10.3' '10.4-11.1' '11.2-20.6'\n '13.9-23.2' '28.4-35.7' '23.3-25.7' '25.8-28.3' '9.7-11.2' '12.7-16.7'\n '7.0-9.6' '22.7-24.7' '12.2-19.7' '24.8-27.9' '19.8-22.6' '8.9-10.7'\n '11.9-18.9' '6.2-8.8' '10.8-11.8' '24.2-25.9' '17.7-24.1' '28.2-32.5'\n '26.0-28.1' '5.8-10.2' '10.3-11.3' '11.4-12.7' '12.8-17.8' '22.8-23.8'\n '11.3-20.2' '20.3-22.7' '23.9-29.8' '9.0-10.2' '10.3-11.7' '11.8-19.7'\n '4.1-8.9' '23.5-25.9' '14.2-23.4' '28.6-32.0' '26.0-28.5' '11.2-12.9'\n '10.3-11.1' '13.0-20.1' '6.2-10.2' '24.2-28.7' '11.6-19.3' '19.4-22.2'\n '22.3-24.1' '8.7-10.4' '10.5-11.4' '4.9-8.6' '11.5-17.0' '25.4-27.1'\n '14.7-23.0' '27.2-31.5' '23.1-25.3' '12.3-14.3' '10.8-12.2' '6.2-9.4'\n '21.1-23.8' '14.7-19.9' '20.0-21.0' '23.9-32.3' '5.7-8.2' '9.6-11.3'\n '11.4-27.6' '8.3-9.5' '22.8-24.5' '18.6-22.7' '24.6-27.4' '27.5-35.3'\n '8.2-9.7' '11.0-14.7' '5.5-8.1' '9.8-10.9' '24.7-29.7' '15.4-20.1'\n '20.2-22.7' '22.8-24.6' '9.0-9.8' '6.0-8.9' '9.9-11.9' '12.0-15.9'\n '26.3-28.1' '18.6-24.6' '28.2-31.1' '24.7-26.2' '11.7-15.2' '9.7-11.6'\n '8.0-9.6' '4.6-7.9' '22.6-24.7' '13.3-19.0' '19.1-22.5' '24.8-29.2'\n '5.2-8.1' '11.7-16.4' '8.2-10.1' '10.2-11.6' '22.6-25.1' '16.1-22.5'\n '25.2-28.4' '28.5-31.7' '9.4-10.4' '10.5-13.7' '3.3-8.5' '8.6-9.3'\n '25.2-29.5' '12.2-19.6' '22.9-25.1' '19.7-22.8' '4.6-8.6' '10.4-11.4'\n '11.5-18.6' '8.7-10.3' '25.9-28.1' '17.9-22.8' '22.9-25.8' '28.2-32.9'\n '10.9-15.0' '8.1-9.0' '4.4-8.0' '9.1-10.8' 'Estimate not reliable.'\n '22.2-24.9' '14.4-20.5' '20.6-22.1' '8.7-9.8' '11.3-18.5' '9.9-11.2'\n '22.9-25.7' '16.9-22.8' '25.8-27.9' '28.0-33.3' '11.4-15.9' '10.1-11.3'\n '5.5-8.7' '25.1-28.4' '15.9-20.2' '20.3-23.1' '23.2-25.0' '10.4-12.4'\n '9.1-10.3' '12.5-21.1' '5.9-9.0' '26.4-28.9' '18.7-24.0' '24.1-26.3'\n '29.0-32.1' '10.0-11.4' '11.5-15.7' '8.4-9.9' '5.9-8.3' '26.8-30.6'\n '23.9-26.7' '21.2-23.8' '13.1-21.1' '9.1-10.5' '12.4-21.8' '10.6-12.3'\n '27.4-30.5' '30.6-33.5' '19.6-24.7' '24.8-27.3' '12.5-16.2' '9.8-11.3'\n '11.4-12.4' '5.7-9.7' '23.9-25.8' '10.9-21.4' '21.5-23.8' '25.9-30.8'\n '<=8.5' '8.6-10.0' '11.4-17.7' '27.7-29.1' '16.3-24.8' '24.9-27.6'\n '29.2-35.4' '12.1-15.2' '9.1-10.4' '10.5-12.0' '6.6-9.0' '26.6-31.4'\n '20.5-23.4' '13.7-20.4' '23.5-26.5' '6.9-8.9' '11.4-20.3' '10.0-11.3'\n '29.6-33.6' '17.0-24.2' '24.3-27.4' '27.5-29.5' '11.1-12.7' '7.0-9.8'\n '12.8-15.2' '9.9-11.0' '24.4-26.1' '11.8-21.0' '26.2-29.3' '21.1-24.3'\n '5.4-8.8' '10.6-11.8' '8.9-10.5' '11.9-20.1' '27.4-29.4' '16.7-24.5'\n '29.5-33.8' '24.6-27.3' '12.6-17.7' '11.3-12.5' '6.7-9.7' '14.4-21.3'\n '26.2-30.8' '21.4-24.3' '8.8-9.8' '9.9-11.6' '<=8.7' '11.7-17.9'\n '27.8-30.0' '19.5-25.3' '30.1-32.9' '25.4-27.7' '11.0-12.7' '12.8-18.4'\n '9.5-10.9' '5.9-9.4' '26.4-33.6' '20.8-24.1' '12.7-20.7' '24.2-26.3'\n '10.6-12.2' '12.3-17.2' '5.6-8.6' '8.7-10.5' '30.5-35.5' '15.5-25.2'\n '25.3-27.7' '27.8-30.4' '5.9-9.2' '11.0-12.1' '12.2-17.8' '20.4-23.5'\n '12.4-20.3' '27.1-34.4' '23.6-27.0' '10.4-11.5' '8.8-10.3' '4.6-8.7'\n '11.6-20.1' '24.0-27.1' '15.3-23.9' '27.2-30.3' '30.4-36.5' '12.6-17.0'\n '7.2-9.5' '9.6-11.2' '20.5-24.2' '14.3-20.4' '26.7-30.9' '24.3-26.6'\n '6.8-9.1' '9.2-10.7' '12.5-17.2' '10.8-12.4' '23.9-27.2' '17.2-23.8'\n '30.3-38.1' '27.3-30.2' '11.7-13.0' '13.1-15.7' '7.4-10.1' '26.4-37.0'\n '11.8-20.5' '20.6-24.1' '9.2-10.3' '12.5-15.5' '29.7-39.3' '16.0-24.2'\n '27.5-29.6' '12.8-15.7' '7.9-9.5' '25.6-35.4' '23.5-25.5' '11.1-12.9'\n '6.4-9.5' '9.6-11.0' '13.0-20.4' '27.2-29.6' '18.6-24.4' '29.7-38.0'\n '24.5-27.1' '10.0-11.5' '12.8-17.6' '11.6-12.7' '5.6-9.9' '27.3-33.7'\n '10.4-21.6' '24.4-27.2' '21.7-24.3' '11.3-12.8' '7.0-9.9' '12.9-20.9'\n '30.7-35.5' '17.1-24.9' '28.6-30.6' '25.0-28.5' '8.3-10.0' '10.1-11.0'\n '11.1-12.4' '12.5-16.0' '25.3-27.5' '21.9-25.2' '16.4-21.8' '27.6-35.7'\n '12.8-19.3' '11.3-12.7' '28.0-30.1' '19.2-26.1' '30.2-36.8' '26.2-27.9'\n '11.4-12.9' '13.0-20.8' '6.6-9.5']\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"<p><b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# rename indicators for better readability</b><p>","metadata":{}},{"cell_type":"code","source":"# Rename the columns for better readability\nindicator_rename_map = {\n    'Took Prescription Medication for Mental Health, Last 4 Weeks': 'Took Medication',\n    'Received Counseling or Therapy, Last 4 Weeks': 'Received Counseling or Therapy',\n    'Took Prescription Medication for Mental Health And/Or Received Counseling or Therapy, Last 4 Weeks': 'Took medication AND/OR therapy',\n    'Needed Counseling or Therapy But Did Not Get It, Last 4 Weeks': \"Needed therapy but didn't get it\"\n}\n\ndf['Indicator'] = df['Indicator'].replace(indicator_rename_map)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.674523Z","iopub.execute_input":"2025-06-26T19:04:02.67481Z","iopub.status.idle":"2025-06-26T19:04:02.841807Z","shell.execute_reply.started":"2025-06-26T19:04:02.674788Z","shell.execute_reply":"2025-06-26T19:04:02.838598Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Indicator'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/548523884.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Indicator'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Indicator'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicator_rename_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Indicator'"],"ename":"KeyError","evalue":"'Indicator'","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"\n# Visualize the distribution of the target variable to ensure we have enough of each category\nplt.figure(figsize=(10, 4))\nsns.countplot(data=df, x='Indicator', color='green', linewidth=0.2, edgecolor='gray', alpha=0.4)\nplt.xticks(ticks=np.arange(4), labels=['Medication', 'Therapy', 'Medication Or Therapy', 'Unmet Need'], fontsize=10)  # Adjust font size for x-axis ticks\nplt.yticks(fontsize=8)  # Adjust font size for y-axis ticks\nplt.title('Distribution of Target')\nplt.xlabel(\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.842716Z","iopub.status.idle":"2025-06-26T19:04:02.843205Z","shell.execute_reply.started":"2025-06-26T19:04:02.843002Z","shell.execute_reply":"2025-06-26T19:04:02.843025Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualizing missing data, dropping rows with smallest % of missing data","metadata":{}},{"cell_type":"code","source":"\n\n# Step 1: Visualize missing data\nplt.figure(figsize=(8, 4))\nmissing_data = df.isnull().mean().sort_values(ascending=False) * 100\nsns.barplot(x=missing_data.values, y=missing_data.index, palette='viridis')\nplt.xticks(fontsize=8)  # Adjust font size for x-axis ticks\nplt.yticks(fontsize=8)  # Adjust font size for y-axis ticks\nplt.xlim(0, 100)  # Set x-axis limit to 100%\nplt.axvline(x=20, color='gray', linestyle='--', linewidth=0.5)\nplt.axvline(x=40, color='gray', linestyle='--', linewidth=0.5)\nplt.axvline(x=60, color='gray', linestyle='--', linewidth=0.5)\nplt.axvline(x=80, color='gray', linestyle='--', linewidth=0.5)\nplt.title('Percentage of Missing Values by Column')\nplt.xlabel('Percent Missing')\nplt.ylabel('')\nplt.tight_layout()\n\nclear_output()\nplt.show()\n\n# Step 2: Count rows before and after dropping rows with missing core values\ninitial_row_count = len(df)\nfiltered_df = df.dropna(subset=['Value', 'LowCI', 'HighCI'])\nfiltered_row_count = len(filtered_df)\nrows_removed = initial_row_count - filtered_row_count\n\n# Step 3: Calculate percentage of data removed\npercent_removed = (rows_removed / initial_row_count) * 100\n\n# Display results\nprint(\"=== Missing Data Stats ===\")\nprint(missing_data)\n\nprint(\"\\n=== Row Count Analysis ===\")\nprint(f\"Initial Rows: {initial_row_count}\")\nprint(f\"Rows After Removal: {filtered_row_count}\")\nprint(f\"Rows Removed: {rows_removed}\")\nprint(f\"Percent Removed: {percent_removed:.2f}%\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.845219Z","iopub.status.idle":"2025-06-26T19:04:02.845612Z","shell.execute_reply.started":"2025-06-26T19:04:02.845418Z","shell.execute_reply":"2025-06-26T19:04:02.845438Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<span style=\"margin-left: 24px; display:inline-block; color=gray, font=bold\"> <b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Understanding the impact of dropping the missing data on distribution, equity outcomes of the data.</b></span>","metadata":{}},{"cell_type":"code","source":"# Step 1: Find rows that were dropped\nmissing_ci_rows = df[df[['Value', 'LowCI', 'HighCI']].isnull().any(axis=1)]\n\n# Step 2: How many are we talking about?\nprint(f\"Rows with missing Value, LowCI, or HighCI: {len(missing_ci_rows)}\")\n\n# Step 3: Summarize by Indicator and Subgroup\nsummary_missing = missing_ci_rows.groupby(['Indicator', 'Subgroup']).size().reset_index(name='Count')\nprint(summary_missing.sort_values('Count', ascending=False).head(10))\n\n# Optional: check how many have meaningful 'Confidence Interval' values\nhas_ci_string = missing_ci_rows['Confidence Interval'].notnull().sum()\nprint(f\"Rows with missing LowCI/HighCI but populated 'Confidence Interval': {has_ci_string}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.846681Z","iopub.status.idle":"2025-06-26T19:04:02.847273Z","shell.execute_reply.started":"2025-06-26T19:04:02.846916Z","shell.execute_reply":"2025-06-26T19:04:02.846935Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\n# Custom colors for each plot\npalette_list = ['Blues_d', 'Greens_d', 'Oranges_d']  \n\ndef plot_top_missing_impact(df, group_col, ax, palette, top_n=10):\n    counts_before = df[group_col].value_counts()\n    counts_after = df.dropna(subset=['Value', 'LowCI', 'HighCI'])[group_col].value_counts()\n\n    impact_df = pd.DataFrame({\n        'Before Removal': counts_before,\n        'After Removal': counts_after\n    }).fillna(0)\n\n    impact_df['Removed'] = impact_df['Before Removal'] - impact_df['After Removal']\n    impact_df['Percent Removed'] = (impact_df['Removed'] / impact_df['Before Removal']) * 100\n    impact_df = impact_df.sort_values(by='Percent Removed', ascending=False).head(top_n)\n\n    # Plot with custom color\n    sns.barplot(x=impact_df['Percent Removed'], y=impact_df.index, ax=ax, palette=palette)\n    ax.set_title(f'{group_col}: Top {top_n} Groups by % Removed', fontsize=10, color='black')\n    ax.set_xlim(0, 25)\n    ax.tick_params(axis='x', labelsize=6)\n    ax.axvline(x=5, color='gray', linestyle=\":\", linewidth=0.5)\n    ax.axvline(x=10, color='gray', linestyle=\":\", linewidth=0.5)\n    ax.axvline(x=15, color='gray', linestyle=\":\", linewidth=0.5)\n    ax.set_xlabel('Percent Removed')\n    ax.set_ylabel(group_col)\n    ax.tick_params(axis='x', labelsize=8)\n    ax.tick_params(axis='y', labelsize=8)\n    for spine in ax.spines.values():\n        spine.set_linewidth(0.2)\n\n# Set up the figure layout\ngroup_cols = ['Subgroup', 'State', 'Indicator']\nn_groups = len(group_cols)\n\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 6))\naxes = axes.flatten()\n\n# Plot each with a unique color palette\nfor i, col in enumerate(group_cols):\n    plot_top_missing_impact(df, col, ax=axes[i], palette=palette_list[i], top_n=10)\n\n# Remove unused subplot (the 4th one)\nfor j in range(n_groups, len(axes)):\n    fig.delaxes(axes[j])\n\nclear_output()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.848503Z","iopub.status.idle":"2025-06-26T19:04:02.848781Z","shell.execute_reply.started":"2025-06-26T19:04:02.848653Z","shell.execute_reply":"2025-06-26T19:04:02.848664Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<span style=\"color:maroon\">Important to also check that all outcome indicators are equally distributed if we plan to do modeling using various outcomes.","metadata":{}},{"cell_type":"code","source":"# Step 1: Count occurrences of each Subgroup before and after dropping rows\nsubgroup_counts_before = df['Subgroup'].value_counts().sort_index()\nsubgroup_counts_after = df.dropna(subset=['Value', 'LowCI', 'HighCI'])['Subgroup'].value_counts().sort_index()\n\n# Step 2: Create a comparison DataFrame\nsubgroup_impact = pd.DataFrame({\n    'Before Removal': subgroup_counts_before,\n    'After Removal': subgroup_counts_after\n})\n\n# Step 3: Calculate rows removed and percent change\nsubgroup_impact['Removed'] = subgroup_impact['Before Removal'] - subgroup_impact['After Removal']\nsubgroup_impact['Percent Removed'] = (subgroup_impact['Removed'] / subgroup_impact['Before Removal']) * 100\n\n# Step 4: Sort by percent removed\nsubgroup_impact_sorted = subgroup_impact.sort_values(by='Percent Removed', ascending=False)\n\n# Display the result\nprint(subgroup_impact_sorted.head(10))  # Adjust number shown as needed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.849971Z","iopub.status.idle":"2025-06-26T19:04:02.850385Z","shell.execute_reply.started":"2025-06-26T19:04:02.850198Z","shell.execute_reply":"2025-06-26T19:04:02.850217Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:green\">What your table shows:\n- missingness by subgroup, and for each row, losing between ~13% and 21% of data — that’s not nothing.\n- will keep the copy of the original data for storytelling and more descriptive analysis\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;However, models require complete outcome data. \nmost models (regression, tree-based, etc.) can’t learn patterns if the target variable (Value) or associated uncertainty (LowCI, HighCI) is missing. \n\n<span style=\"color:green\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- To preserve more context: I will be keeping subgroup, Indicator, Time Period, and any demographic flags as features.","metadata":{}},{"cell_type":"markdown","source":"<p style=\"margin-left: 20px;\"> so far</p>\n<pre>&nbsp;&nbsp;&nbsp;&nbsp;✅ Renamed and reviewed your outcome (y) variable\n&nbsp;&nbsp;&nbsp;&nbsp;✅ Assessed and dropped rows with missing key metrics (Value, LowCI, HighCI)\n&nbsp;&nbsp;&nbsp;&nbsp;✅ Evaluated the impact on subgroup representation</pre>\n","metadata":{}},{"cell_type":"code","source":"# Time for conversions\n\n# Replace obvious anomalies and extract numeric part\ndf['Phase_Clean'] = df['Phase'].replace('-1', 'Unknown')  # Optional: handle '-1'\ndf['Phase_Clean'] = df['Phase_Clean'].str.extract(r'(\\d+\\.?\\d*)')  # Extract numeric part\ndf['Phase_Clean'] = pd.to_numeric(df['Phase_Clean'], errors='coerce')  # Convert to float\n\n\ndef classify_subgroup(sub):\n    if 'years' in sub:\n        return 'Age'\n    elif sub in ['Male', 'Female']:\n        return 'Sex'\n    elif 'Hispanic' in sub or 'race' in sub:\n        return 'Race/Ethnicity'\n    elif 'diploma' in sub or 'degree' in sub:\n        return 'Education'\n    elif 'disability' in sub:\n        return 'Disability Status'\n    elif 'gender' in sub:\n        return 'Gender Identity'\n    elif 'Straight' in sub or 'Gay' in sub or 'Bisexual' in sub:\n        return 'Sexual Orientation'\n    elif sub in df['State'].unique():\n        return 'State'\n    elif sub == 'United States':\n        return 'National'\n    else:\n        return 'Other'\n\ndf['Subgroup_Category'] = df['Subgroup'].apply(classify_subgroup)\n\n# Convert date columns\ndf['Time Period Start Date'] = pd.to_datetime(df['Time Period Start Date'])\ndf = df.sort_values('Time Period Start Date')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.851343Z","iopub.status.idle":"2025-06-26T19:04:02.851605Z","shell.execute_reply.started":"2025-06-26T19:04:02.851482Z","shell.execute_reply":"2025-06-26T19:04:02.851494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.852686Z","iopub.status.idle":"2025-06-26T19:04:02.853006Z","shell.execute_reply.started":"2025-06-26T19:04:02.852818Z","shell.execute_reply":"2025-06-26T19:04:02.852849Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"font-size:20px;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;📈 Part 1: Trends in Use of Medication & Therapy since COVID</p>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"text-indent: 2em;\">“How did use of medication and therapy change over time for each subgroup (e.g., by age, race/ethnicity, gender, etc.)?”</p>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Filter to \"Received Counseling or Therapy\" and Race/Ethnicity\ntherapy_race = df[\n    (df['Indicator'] == 'Took Medication') &\n    (df['Subgroup_Category'] == 'Race/Ethnicity')\n].copy()\n\n# Convert date\ntherapy_race['Time Period Start Date'] = pd.to_datetime(therapy_race['Time Period Start Date'])\ntherapy_race = therapy_race.sort_values('Time Period Start Date')\n\n# Plot\nplt.figure(figsize=(12, 6))\nsns.lineplot(\n    data=therapy_race,\n    x='Time Period Start Date',\n    y='Value',\n    hue='Subgroup',\n    marker='o'\n)\nplt.title('Medication Use Over Time by Race/Ethnicity')\nplt.xlabel('Date')\nplt.ylabel('% of Adults')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.854685Z","iopub.status.idle":"2025-06-26T19:04:02.855016Z","shell.execute_reply.started":"2025-06-26T19:04:02.854863Z","shell.execute_reply":"2025-06-26T19:04:02.854876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Rolling average (3-month)\n\n\nimport matplotlib.dates as mdates\n\n# Ensure the datetime column is correct and sorted\ntherapy_race['Time Period Start Date'] = pd.to_datetime(therapy_race['Time Period Start Date'])\ntherapy_race = therapy_race.sort_values(['Subgroup', 'Time Period Start Date'])\n\n# 3-month rolling average by subgroup\ntherapy_race['Rolling Value'] = therapy_race.groupby('Subgroup')['Value'].transform(\n    lambda x: x.rolling(window=3, min_periods=1).mean()\n)\n\n# Unique ethnic groups\nethnic_groups = sorted(therapy_race['Subgroup'].unique())  # sort for consistent order\nn_groups = len(ethnic_groups)\nplots_per_row = 2\nn_rows = int(np.ceil(n_groups / plots_per_row))\n\n# Setup subplots\nfig, axes = plt.subplots(n_rows, plots_per_row, figsize=(16, 4 * n_rows), sharex=False)\naxes = axes.flatten()\n\n# Get color palette\ncolors = sns.color_palette(\"husl\", n_groups)\n\n# Plot each group\nfor idx, (group, ax) in enumerate(zip(ethnic_groups, axes)):\n    group_data = therapy_race[therapy_race['Subgroup'] == group]\n\n    # Plot rolling line\n    ax.plot(group_data['Time Period Start Date'], group_data['Rolling Value'],\n            linewidth=2, color=colors[idx])\n\n    # Style title and labels\n    ax.set_title(group, fontsize=14, fontweight='bold')\n    ax.set_ylabel('% of Adults', fontsize=12)\n    ax.set_xlabel('Date', fontsize=11)\n\n    # Date ticks on all subplots\n    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n    ax.tick_params(axis='x', labelrotation=45)\n\n    # Gridlines for clarity\n    ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n\n# Remove any unused axes\nfor j in range(len(ethnic_groups), len(axes)):\n    fig.delaxes(axes[j])\n\n# Final layout adjustments\nplt.suptitle('3-Month Rolling Average: Medication Use by Race/Ethnicity',\n             fontsize=18, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.subplots_adjust(hspace=0.4)\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.85603Z","iopub.status.idle":"2025-06-26T19:04:02.856335Z","shell.execute_reply.started":"2025-06-26T19:04:02.856176Z","shell.execute_reply":"2025-06-26T19:04:02.856192Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<pre>Event\t            Approx Date\nU.S. Lockdowns Start\t<i>Mar 15, 2020</i>\nFirst Stimulus Package\t<i>Apr 1, 2020</i>\nPfizer Vaccine Approval\t<i>Dec 11, 2020</i>\nMass Vaccination Begins\t<i>Jan 2021</i>\nDelta Variant Surge\t<i>Jul 2021</i>\nOmicron Surge\t        <i>Dec 2021</i>\nMajor Reopenings\t<i>Mar–Jun 2022</i></pre>","metadata":{}},{"cell_type":"code","source":"from scipy.stats import ttest_ind\n\n# Step 1: Add lockdown label\nlockdown_start = pd.to_datetime(\"2020-03-15\")\nvaccine_approval = pd.to_datetime(\"2020-12-11\")\ndf['During Lockdown'] = df['Time Period Start Date'].between(lockdown_start, vaccine_approval)\ndf['Lockdown Label'] = df['During Lockdown'].map({True: 'Lockdown', False: 'Post-Lockdown'})\n\n# Step 2: Filter to unmet need only\nunmet = df[df['Indicator'].str.contains(\"didn't get\", case=False)]\n\n# Step 3: Compute means and top 5 change\nunmet_mean = unmet.groupby(['Subgroup', 'Lockdown Label'])['Value'].mean().unstack()\nunmet_mean['Change'] = unmet_mean['Lockdown'] - unmet_mean['Post-Lockdown']\ntop5_unmet = unmet_mean.nlargest(5, 'Change')\n\n# Step 4: T-tests for top 5\nttest_results = []\nfor subgroup in top5_unmet.index:\n    lock_vals = unmet[(unmet['Subgroup'] == subgroup) & (unmet['Lockdown Label'] == 'Lockdown')]['Value']\n    post_vals = unmet[(unmet['Subgroup'] == subgroup) & (unmet['Lockdown Label'] == 'Post-Lockdown')]['Value']\n    t_stat, p_val = ttest_ind(lock_vals, post_vals, equal_var=False, nan_policy='omit')\n    significance = 'Significant' if p_val < 0.05 else 'Not Significant'\n    ttest_results.append({\n        'Subgroup': subgroup,\n        'Lockdown Mean': lock_vals.mean(),\n        'Post-Lockdown Mean': post_vals.mean(),\n        'Change': lock_vals.mean() - post_vals.mean(),\n        'T-stat': t_stat,\n        'P-value': p_val,\n        'Significance': significance\n    })\n\nttest_df = pd.DataFrame(ttest_results).sort_values('P-value')\n\n# Step 5: Visualize\nplt.figure(figsize=(10, 3))\nsns.barplot(\n    data=ttest_df,\n    y='Subgroup',\n    x='Change',\n    hue='Significance',\n    dodge=False,\n    palette={'Significant': 'crimson', 'Not Significant': 'gray'}\n)\nplt.axvline(x=0, color='black', linewidth=0.8, linestyle='--')\nplt.title(\"Top 5 Increases in Unmet Mental Health Need (Lockdown vs. Post-Lockdown)\", fontsize=12, color='darkblue')\nplt.xlabel(\"Change in % Reporting Unmet Need (Lockdown - Post-Lockdown)\")\nplt.ylabel(\"Subgroup\")\nplt.tight_layout()\nplt.show()\n\n# Optional: Display the table\nprint(\"=== T-Test Results for Unmet Need ===\")\ndisplay(ttest_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.857225Z","iopub.status.idle":"2025-06-26T19:04:02.857519Z","shell.execute_reply.started":"2025-06-26T19:04:02.857387Z","shell.execute_reply":"2025-06-26T19:04:02.857401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom IPython.display import display, HTML\n\n# Step 1: Copy and format your DataFrame\ntable_df = ttest_df.copy()  # Replace with the correct DataFrame containing t-test results\n# Ensure the columns are strings before using .str.replace()\ntable_df['Lockdown Mean'] = table_df['Lockdown Mean'].astype(str).str.replace('%', '').astype(float).round(1)\ntable_df['Post-Lockdown Mean'] = table_df['Post-Lockdown Mean'].astype(str).str.replace('%', '').astype(float).round(1)\ntable_df['Change'] = table_df['Change'].astype(float).round(1)\n\n# Step 2: Add larger red asterisk to significant values\ntable_df['Change'] = table_df.apply(\n    lambda row: f\"{row['Change']:+.1f}%<span style='color:maroon; font-size:16px; font-weight:bold;'>*</span>\"\n    if row['Significance'] == 'Significant' else f\"{row['Change']:+.1f}%\",\n    axis=1\n)\n\n# Step 3: Keep relevant columns\ndisplay_table = table_df[['Subgroup', 'Lockdown Mean', 'Post-Lockdown Mean', 'Change']]\n\n# Step 4: Build styled HTML table and note\ntable_html = display_table.to_html(escape=False, index=False)\nnote_html = \"<div style='color:maroon; font-weight:bold; font-size:13px; margin-top:12px;'>Note: * indicates statistical significance at p &lt; 0.05.</div>\"\n\n# Step 5: Display table + note\ndisplay(HTML(f\"<div style='color:maroon; font-weight:bold; font-size:13px; margin-top:12px; margin-bottom:12px;'>Change in Mental Health Service Use by Age Group</div>{table_html}{note_html}\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.858508Z","iopub.status.idle":"2025-06-26T19:04:02.85878Z","shell.execute_reply.started":"2025-06-26T19:04:02.858657Z","shell.execute_reply":"2025-06-26T19:04:02.858668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# 1. Remap groups and indicators\nsubgroup_map = {\n    'Hispanic or Latino': 'Hispanic',\n    'Non-Hispanic White, single race': 'White (NH)',\n    'Non-Hispanic Black, single race': 'Black (NH)',\n    'Non-Hispanic Asian, single race': 'Asian (NH)',\n    'Non-Hispanic, other races and multiple races': 'Other/Multiracial (NH)'\n}\nindicator_map = {\n    'Took Prescription Medication for Mental Health, Last 4 Weeks': 'Took Medication',\n    'Received Counseling or Therapy, Last 4 Weeks': 'Received Counseling or Therapy',\n    'Took Prescription Medication for Mental Health And/Or Received Counseling or Therapy, Last 4 Weeks': 'Took Medication And/Or Therapy',\n    'Needed Counseling or Therapy But Did Not Get It, Last 4 Weeks': 'Unmet Need'\n}\ndf['Subgroup'] = df['Subgroup'].replace(subgroup_map)\ndf['Indicator'] = df['Indicator'].replace(indicator_map)\n\n# 2. Add lockdown labels\ndf['Time Period Start Date'] = pd.to_datetime(df['Time Period Start Date'], errors='coerce')\nlockdown_start = pd.to_datetime(\"2020-03-15\")\nvaccine_approval = pd.to_datetime(\"2020-12-11\")\ndf['Lockdown Label'] = df['Time Period Start Date'].between(lockdown_start, vaccine_approval).map({True: 'Lockdown', False: 'Post-Lockdown'})\n\n# 3. Filter for race subgroups only\nrace_groups = list(subgroup_map.values())\ndf_race = df[df['Subgroup'].isin(race_groups)]\n\n# 4. Run t-tests and store only significant results\nindicators = list(indicator_map.values())\nsig_results = []\n\nfor indicator in indicators:\n    for group in race_groups:\n        subset = df_race[(df_race['Indicator'] == indicator) & (df_race['Subgroup'] == group)]\n        lock = subset[subset['Lockdown Label'] == 'Lockdown']['Value']\n        post = subset[subset['Lockdown Label'] == 'Post-Lockdown']['Value']\n        if lock.empty or post.empty:\n            continue\n        t_stat, p_val = ttest_ind(lock, post, equal_var=False, nan_policy='omit')\n        if p_val < 0.05:\n            sig_results.append({\n                'Race/Ethnicity': group,\n                'Indicator': indicator,\n                'Change': post.mean() - lock.mean()\n            })\n\n# 5. Create DataFrame of significant results\nsig_df = pd.DataFrame(sig_results)\n\n# 6. Create side-by-side subplots (1 per indicator with significant values)\nif not sig_df.empty:\n    unique_indicators = sig_df['Indicator'].unique()\n    fig, axes = plt.subplots(1, len(unique_indicators), figsize=(6 * len(unique_indicators), 3), sharey=True)\n\n    # Ensure axes is iterable\n    if len(unique_indicators) == 1:\n        axes = [axes]\n\n    for ax, indicator in zip(axes, unique_indicators):\n        plot_data = sig_df[sig_df['Indicator'] == indicator]\n        bars = sns.barplot(\n            data=plot_data,\n            y='Race/Ethnicity',\n            x='Change',\n            color='crimson',\n            ax=ax\n        )\n        ax.axvline(0, color='black', linestyle='--', linewidth=0.7)\n        ax.set_title(indicator, fontsize=11)\n        ax.set_xlabel(\"Change (%)\")\n        ax.xaxis.set_major_locator(ticker.MultipleLocator(0.5))  # Set x-ticks every 0.5%\n        ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f\"{x:.1f}%\"))  # Format ticks with %\n        ax.grid(True, axis='x', linestyle='--', linewidth=0.3, color='gray')  # Add vertical gridlines\n        if ax != axes[0]:\n            ax.set_ylabel(\"\")\n        else:\n            ax.set_ylabel(\"Race/Ethnicity\")\n\n        # Add labels inside bars\n        for container in ax.containers:\n            for bar in container:\n                value = bar.get_width()\n                label = f\"{value:+.1f}%\"\n                x_pos = value - 0.5 if value > 0 else value + 0.5\n                ax.text(x_pos, bar.get_y() + bar.get_height() / 2,\n                        label,\n                        va='center',\n                        ha='right' if value > 0 else 'left',\n                        fontsize=12,\n                        color='white')\n\n    plt.suptitle(\"Significant Changes in Mental Health Service Use by Race/Ethnicity\", fontsize=14, color='darkgray')\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"No significant results to display.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.860376Z","iopub.status.idle":"2025-06-26T19:04:02.860676Z","shell.execute_reply.started":"2025-06-26T19:04:02.860551Z","shell.execute_reply":"2025-06-26T19:04:02.860563Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Part 1: Analyze Differences by Education Level\nStep-by-step:\n- Filter or map your education-related subgroups (e.g., \"High school diploma or GED\", \"Bachelor’s degree or higher\")\n\n- Use the same t-test framework (Lockdown vs Post-Lockdown)\n\nFocus on:\n- Took Medication\n- Received Counseling\n- Took Medication and/or Counseling\n- Unmet Need\n","metadata":{}},{"cell_type":"code","source":"education_levels = [\n    'Less than a high school diploma',\n    'High school diploma or GED',\n    \"Some college/Associate's degree\",\n    \"Bachelor's degree or higher\"\n]\n\ndf_edu = df[df['Subgroup'].isin(education_levels)]\n\nedu_results = []\n\nfor indicator in indicators:\n    for edu in education_levels:\n        subset = df_edu[(df_edu['Indicator'] == indicator) & (df_edu['Subgroup'] == edu)]\n        lock_vals = subset[subset['Lockdown Label'] == 'Lockdown']['Value']\n        post_vals = subset[subset['Lockdown Label'] == 'Post-Lockdown']['Value']\n        if lock_vals.empty or post_vals.empty:\n            continue\n        t_stat, p_val = ttest_ind(lock_vals, post_vals, equal_var=False, nan_policy='omit')\n        significance = 'Significant' if p_val < 0.05 else 'Not Significant'\n        edu_results.append({\n            'Education Level': edu,\n            'Indicator': indicator,\n            'Change': post_vals.mean() - lock_vals.mean(),\n            'P-value': p_val,\n            'Significance': significance\n        })\n\nedu_df = pd.DataFrame(edu_results)\nsig_df = edu_df[edu_df['Significance'] == 'Significant']\n\n# Define color palette manually per indicator\npalette = {\n    'Took Medication': 'darkgreen',\n    'Received Counseling or Therapy': 'maroon',\n    'Took Medication And/Or Therapy': 'darkgreen',\n    'Unmet Need': 'maroon'\n}\n\n# Plot\nplt.figure(figsize=(10, 4))\nbarplot = sns.barplot(data=sig_df, x='Change', y='Education Level', hue='Indicator', dodge=True, palette=palette)\n\n# Add value labels inside bars\nfor container in barplot.containers:\n    for bar in container:\n        width = bar.get_width()\n        label = f'{width:+.1f}%'\n        x_pos = width - 0.2 if width > 0 else width + 0.2\n        barplot.text(\n            x=x_pos,\n            y=bar.get_y() + bar.get_height() / 2,\n            s=label,\n            color='white',\n            ha='right',\n            va='center',\n            fontsize=12\n        )\n\nplt.axvline(0, color='black', linestyle='--', linewidth=0.7)\nplt.title(\"Significant Changes in Mental Health Outcomes by Education Level (Post vs Lockdown)\", fontsize=12)\nplt.xlabel(\"Change in % Reporting\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.86182Z","iopub.status.idle":"2025-06-26T19:04:02.862199Z","shell.execute_reply.started":"2025-06-26T19:04:02.862017Z","shell.execute_reply":"2025-06-26T19:04:02.862034Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✅ Model Objective (clean version):\n-Compare two periods:\n-- Pre-lockdown (baseline)\n-- During-lockdown (treatment)\n\n- Compare across subgroups — e.g., by age or other dimensions\n- Use Post-lockdown observations only as a comparison (not a second treatment)\n\n🛠 What We’ll Do:\n1. Define Pre-Lockdown and During-Lockdown only\n2. Filter out post-lockdown data\n3. Create treated, time, and interaction (DiD) variables\n4. Fit a linear regression model\n\n","metadata":{}},{"cell_type":"code","source":"\nimport statsmodels.formula.api as smf\n\n\ndf_unmet = df[df['Indicator'] == \"Needed therapy but didn't get it\"].copy()\n\n# Define key time windows\npre_lockdown_end = pd.to_datetime(\"2020-03-14\")\nlockdown_start = pd.to_datetime(\"2020-03-15\")\nvaccine_approval = pd.to_datetime(\"2020-12-11\")\n\n# Filter to just pre-lockdown and during-lockdown\ndf_unmet = df_unmet[df_unmet['Time Period Start Date'] <= vaccine_approval]\n\n# Create DiD structure\ndf_unmet['time'] = (df_unmet['Time Period Start Date'] >= lockdown_start).astype(int)\ndf_unmet['treated'] = (df_unmet['Group'] == \"By Age\").astype(int)  # Example: By Age is \"treated\" group\ndf_unmet['did'] = df_unmet['time'] * df_unmet['treated']\n\n# Fit the DiD model\nmodel = smf.ols('Value ~ treated + time + did', data=df_unmet).fit()\nprint(model.summary())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.863308Z","iopub.status.idle":"2025-06-26T19:04:02.863661Z","shell.execute_reply.started":"2025-06-26T19:04:02.863482Z","shell.execute_reply":"2025-06-26T19:04:02.863498Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<b> R score is very low, and significant concerns about multicollinearity.  Lets try different subgroups instead.","metadata":{}},{"cell_type":"markdown","source":"✅ Python Code: DiD for Age Groups (18–59)","metadata":{}},{"cell_type":"code","source":"\n# Filter for relevant indicator and age groups\nage_groups = ['18 - 29 years', '30 - 39 years', '40 - 49 years', '50 - 59 years']\ndf_sub = df[\n    (df['Indicator'] == \"Needed therapy but didn't get it\") &\n    (df['Group'] == 'By Age') &\n    (df['Subgroup'].isin(age_groups))\n].copy()\n\n# Define lockdown window\nlockdown_start = pd.to_datetime(\"2020-03-15\")\nvaccine_approval = pd.to_datetime(\"2020-12-11\")\ndf_sub = df_sub[df_sub['Time Period Start Date'] <= vaccine_approval]\n\n# Create time and treatment indicators\ndf_sub['time'] = (df_sub['Time Period Start Date'] >= lockdown_start).astype(int)\n\n# Encode age group as treatment categories\ndf_sub['treated'] = (df_sub['Subgroup'] == '18 - 29 years').astype(int)\ndf_sub.loc[df_sub['Subgroup'] == '40 - 49 years', 'treated'] = 2\ndf_sub.loc[df_sub['Subgroup'] == '50 - 59 years', 'treated'] = 3\n\n# Label group names\ndf_sub['treated_str'] = df_sub['treated'].map({\n    0: 'control',\n    1: '18_29',\n    2: '40_49',\n    3: '50_59'\n})\n\n# Create interaction term between time and treatment\ndf_sub['interaction'] = df_sub['time'].astype(str) + '_' + df_sub['treated_str']\n\n# One-hot encode interaction variables\ndf_encoded = pd.get_dummies(df_sub, columns=['treated_str', 'interaction'], drop_first=True)\n\n# Construct DiD regression formula\ninteraction_terms = '+'.join([col for col in df_encoded.columns if col.startswith('interaction_')])\nformula = f\"Value ~ time + {interaction_terms} + C(State)\"\n\n# Fit the model\nmodel = smf.ols(formula, data=df_encoded).fit()\n\n# Print summary\nprint(model.summary())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.8655Z","iopub.status.idle":"2025-06-26T19:04:02.86581Z","shell.execute_reply.started":"2025-06-26T19:04:02.865664Z","shell.execute_reply":"2025-06-26T19:04:02.865679Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This will estimate and compare how unmet mental health needs changed during lockdown for:\n18–29 (reference)\n30–39 (control)\n40–49\n50–59\n\n📊 Interpretation of Key Results (Interaction Terms)\n<pre>Interaction Term\tCoefficient\tP-value\t      Interpretation\ninteraction_1_control\t−3.64\t     < 0.001 ✅\t    30–39 (control) had a smaller increase than 18–29\ninteraction_1_40_49\t−7.28\t     < 0.001 ✅\t    40–49 saw much less increase than 18–29\ninteraction_1_50_59\t−9.79\t     < 0.001 ✅     50–59 had the least increase in unmet need","metadata":{}},{"cell_type":"code","source":"\nlockdown_start = pd.to_datetime(\"2020-03-15\")\nvaccine_approval = pd.to_datetime(\"2020-12-11\")\n\n# Filter for unmet need and race/ethnicity group\ndf_race = df[\n    (df['Indicator'] == \"Needed therapy but didn't get it\") &\n    (df['Group'] == 'By Race/Hispanic ethnicity')\n].copy()\n\n# Label periods for comparison\ndf_race['Period'] = pd.cut(\n    df_race['Time Period Start Date'],\n    bins=[lockdown_start, vaccine_approval, pd.Timestamp.max],\n    labels=['Lockdown', 'Post-Vaccine']\n)\n\n# Remove rows outside the defined periods\ndf_race = df_race[df_race['Period'].notna()]\n\n# Group by race and period, then calculate mean unmet need\nsummary = df_race.groupby(['Subgroup', 'Period'])['Value'].mean().unstack()\nsummary['Change'] = summary['Post-Vaccine'] - summary['Lockdown']\n\n# Sort by change for better visuals\nsummary_sorted = summary.sort_values(by='Change', ascending=False)\n\n# Plotting\nplt.figure(figsize=(10, 4))\nbars = plt.barh(summary_sorted.index, summary_sorted['Change'], color='skyblue')\n\n# Aesthetic touches\nplt.axvline(0, color='gray', linestyle='--')\nplt.title(\"Change in Unmet Mental Health Need\\n(Lockdown → Post-Vaccine) by Race/Ethnicity\")\nplt.xlabel(\"Change in % Reporting Unmet Need\")\nplt.ylabel(\"Race/Ethnicity\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.868664Z","iopub.status.idle":"2025-06-26T19:04:02.869473Z","shell.execute_reply.started":"2025-06-26T19:04:02.869261Z","shell.execute_reply":"2025-06-26T19:04:02.86928Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Filter to race-based groups and the right indicator\ndf_race = df[\n    (df['Indicator'] == \"Needed therapy but didn't get it\") &\n    (df['Group'] == 'By Race/Hispanic ethnicity')\n].copy()\n\n# Add a 'Period' column: Lockdown vs Post-Vaccine\ndf_race['Period'] = pd.cut(\n    df_race['Time Period Start Date'],\n    bins=[lockdown_start, vaccine_approval, pd.Timestamp.max],\n    labels=['Lockdown', 'Post-Vaccine']\n)\n\n# Drop NA periods (pre-lockdown or invalid dates)\ndf_race = df_race[df_race['Period'].notna()]\ndf_race['Period'] = df_race['Period'].astype(str)\n\n# Run regression: main effects + interaction\nmodel = smf.ols('Value ~ C(Subgroup) + C(Period) + C(Subgroup):C(Period)', data=df_race).fit()\n\n# Print results\nprint(model.summary())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.870669Z","iopub.status.idle":"2025-06-26T19:04:02.87107Z","shell.execute_reply.started":"2025-06-26T19:04:02.870932Z","shell.execute_reply":"2025-06-26T19:04:02.870947Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This tests whether different race/ethnicity groups experienced significantly different changes in unmet mental health need between the lockdown and post-vaccine periods.\n\n🧠 Takeaway\n- Baseline unmet need was significantly different by race (e.g., much higher for multiracial).\n- The change from lockdown to post-vaccine was not significantly different across groups.\n- Suggests disparities existed, but lockdown → vaccine phase <b>didn't change them much.","metadata":{}},{"cell_type":"code","source":"# Filter for gender-based groups and target indicator\ndf_gender = df[\n    (df['Indicator'] == \"Needed therapy but didn't get it\") &\n    (df['Group'] == 'By Sex')\n].copy()\n\n# Define period labels\ndf_gender['Period'] = pd.cut(\n    df_gender['Time Period Start Date'],\n    bins=[lockdown_start, vaccine_approval, pd.Timestamp.max],\n    labels=['Lockdown', 'Post-Vaccine']\n)\n\n# Drop invalid rows\ndf_gender = df_gender[df_gender['Period'].notna()]\ndf_gender['Period'] = df_gender['Period'].astype(str)\n\n# Run regression: unmet need ~ gender + period + interaction\nmodel = smf.ols('Value ~ C(Subgroup) + C(Period) + C(Subgroup):C(Period)', data=df_gender).fit()\n\n# Print results\nprint(model.summary())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.871798Z","iopub.status.idle":"2025-06-26T19:04:02.872113Z","shell.execute_reply.started":"2025-06-26T19:04:02.87196Z","shell.execute_reply":"2025-06-26T19:04:02.871972Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"OLS regression to examine how unmet mental health need (%) changed between males and females, across the lockdown vs. post-vaccine periods.\n\nOverall Fit\nR-squared = 0.904 ✅\n➤ The model explains over 90% of the variance in unmet need — very strong fit.\n\nF-statistic = 193.5, P < 0.001 ✅\n➤ The overall model is highly statistically significant.\n\n✅ SUMMARY IN PLAIN ENGLISH\n- Females had higher unmet need during lockdown than males (by ~5 percentage points).\n- Neither gender showed a significant change from lockdown to post-vaccine.\n- The gender gap persisted, but didn't significantly widen or shrink after the vaccine period.","metadata":{}},{"cell_type":"code","source":"\n# Filter for education group and unmet need\ndf_edu = df[\n    (df['Indicator'] == \"Needed therapy but didn't get it\") &\n    (df['Group'] == 'By Education')\n].copy()\n\n# Define period labels\ndf_edu['Period'] = pd.cut(\n    df_edu['Time Period Start Date'],\n    bins=[lockdown_start, vaccine_approval, pd.Timestamp.max],\n    labels=['Lockdown', 'Post-Vaccine']\n)\ndf_edu = df_edu[df_edu['Period'].notna()]\ndf_edu['Period'] = df_edu['Period'].astype(str)\n\n# Run regression: unmet need ~ education + period + interaction\nmodel = smf.ols('Value ~ C(Subgroup) + C(Period) + C(Subgroup):C(Period)', data=df_edu).fit()\n\n# Display results\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.873066Z","iopub.status.idle":"2025-06-26T19:04:02.873338Z","shell.execute_reply.started":"2025-06-26T19:04:02.873194Z","shell.execute_reply":"2025-06-26T19:04:02.873205Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"People with a Bachelor’s degree or higher had 10.57% unmet need during the lockdown period, which decreased to 8.76% post-vaccine approval. \nThis indicates a decrease of 1.81% in unmet need, which is statistically significant (p < 0.05).\n\n✅ Summary in Plain English\n- People with some college/associate degrees reported the highest unmet need.\n- Those with a high school diploma had the lowest unmet need compared to college grads.\n- Unmet need didn’t change significantly after the vaccine for any education group.","metadata":{}},{"cell_type":"code","source":"# Define coef_main DataFrame with example data\nimport pandas as pd\n\ncoef_main = pd.DataFrame({\n    'Coefficient': [0.5, -0.3, 0.8, -0.1],\n    'CI Lower': [0.2, -0.5, 0.6, -0.3],\n    'CI Upper': [0.8, -0.1, 1.0, 0.1],\n    'Label': ['High School', 'Some College', 'Bachelor\\'s Degree', 'Graduate Degree']\n})\n\n# Re-plot with grid lines added for better readability\nplt.figure(figsize=(10, 3))\nplt.errorbar(coef_main['Coefficient'], coef_main['Label'],\n             xerr=[coef_main['Coefficient'] - coef_main['CI Lower'], coef_main['CI Upper'] - coef_main['Coefficient']],\n             fmt='o', color='darkgreen', ecolor='lightgray', elinewidth=3, capsize=5)\n\nplt.axvline(0, color='gray', linestyle='--')\nplt.grid(axis='x', linestyle=':', color='lightgray')  # Add vertical grid lines\nplt.title(\"Regression Estimates: Main Effect of Education on Unmet Mental Health Need\")\nplt.xlabel(\"Change in Percentage Reporting Unmet Need\")\nplt.ylabel(\"Education Level\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.874314Z","iopub.status.idle":"2025-06-26T19:04:02.874549Z","shell.execute_reply.started":"2025-06-26T19:04:02.874438Z","shell.execute_reply":"2025-06-26T19:04:02.874447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unmet_df = df[df['Indicator'] == 'Unmet Need'].copy()\nprint(\"Rows in unmet_df:\", len(unmet_df))\n\n# Ensure X is defined before using it\nX = unmet_df.drop(columns=['Value', 'Indicator', 'Time Period Start Date', 'Time Period'], errors='ignore')\n\nX = X.dropna()\n\nprint(\"Final shape of X:\", X.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.875191Z","iopub.status.idle":"2025-06-26T19:04:02.875482Z","shell.execute_reply.started":"2025-06-26T19:04:02.87534Z","shell.execute_reply":"2025-06-26T19:04:02.875356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Step 1: Normalize and rename indicator values for clarity\nindicator_map = {\n    'Took Medication': 'Took Medication',\n    'Received Counseling or Therapy': 'Received Counseling or Therapy',\n    'Took medication AND/OR therapy': 'Took Medication And/Or Therapy',\n    \"Needed therapy but didn't get it\": 'Unmet Need'\n}\ndf['Indicator'] = df['Indicator'].str.strip().replace(indicator_map)\n\n# Step 2: Filter for Unmet Need indicator\nunmet_df = df[df['Indicator'] == 'Unmet Need'].copy()\n\n# Safeguard: Check if the filtered DataFrame is empty\nif unmet_df.empty:\n    raise ValueError(\"No rows found with Indicator == 'Unmet Need'. Please check the data or renaming step.\")\n\n# Step 3: Create binary target (e.g., unmet need > 10%)\nunmet_df['High_Unmet_Need'] = (unmet_df['Value'] > 10).astype(int)\n\n# Step 4: Encode categorical variables\ncategorical_cols = ['Subgroup', 'Lockdown Label']\nunmet_df = pd.get_dummies(unmet_df, columns=categorical_cols, drop_first=True)\n\n# Step 5: Define features and target\nX = unmet_df.drop(columns=['Value', 'High_Unmet_Need', 'Indicator', 'Time Period Start Date', 'Time Period'])\ny = unmet_df['High_Unmet_Need']\n\n# Drop potential leakage columns\nleakage_cols = ['Time Period End Date', 'HighCI', 'LowCI', 'Phase', 'Phase_Clean']\nX = X.drop(columns=[col for col in leakage_cols if col in X.columns], errors='ignore')\n\n# Clean X with smarter control\nX = X.apply(pd.to_numeric, errors='coerce')\nX = X.loc[:, X.isnull().mean() < 0.5]  # Drop columns with >50% missing\nX = X.loc[X.isnull().mean(axis=1) < 0.3]  # Drop rows with >30% missing\nX = X.fillna(0)  # Fill remaining NaNs with 0\ny = y.loc[X.index]\n\n# Safeguard: Check if the dataset has enough rows for train-test split\nif X.shape[0] < 2:\n    raise ValueError(\"Not enough data to perform train-test split. Please check your filter criteria or increase your dataset.\")\n\n# Step 6: Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 7: Logistic Regression\nlogreg = LogisticRegression(max_iter=1000)\nlogreg.fit(X_train, y_train)\nlogreg_preds = logreg.predict(X_test)\n\n# Step 8: Random Forest\nforest = RandomForestClassifier(random_state=42)\nforest.fit(X_train, y_train)\nforest_preds = forest.predict(X_test)\n\n# Step 9: Evaluation\nprint(\"\\n=== Logistic Regression ===\")\nprint(classification_report(y_test, logreg_preds))\n\nprint(\"\\n=== Random Forest ===\")\nprint(classification_report(y_test, forest_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.876727Z","iopub.status.idle":"2025-06-26T19:04:02.876994Z","shell.execute_reply.started":"2025-06-26T19:04:02.876876Z","shell.execute_reply":"2025-06-26T19:04:02.876886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Feature importance from Random Forest\nimportances = forest.feature_importances_\nindices = np.argsort(importances)[::-1]\nfeatures = X.columns\n\nplt.figure(figsize=(10, 4))\nsns.barplot(x=importances[indices][:10], y=features[indices][:10], color='darkgreen')\nplt.title('Top 10 Most Important Features (Random Forest)')\nplt.xlabel('Importance Score')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.87798Z","iopub.status.idle":"2025-06-26T19:04:02.878251Z","shell.execute_reply.started":"2025-06-26T19:04:02.878135Z","shell.execute_reply":"2025-06-26T19:04:02.878145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"importances = forest.feature_importances_\nfeature_table = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': importances\n}).sort_values(by='Importance', ascending=False).head(10)\n\nprint(\"=== Feature Importance Table (Random Forest) ===\")\nprint(feature_table.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T19:04:02.879289Z","iopub.status.idle":"2025-06-26T19:04:02.881864Z","shell.execute_reply.started":"2025-06-26T19:04:02.879453Z","shell.execute_reply":"2025-06-26T19:04:02.879468Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✅ possible interpretation of Top Random Forest Features?\n- Subgroup_80 years and above\tThis age group is a strong predictor — people in this group may have had either very high or very low levels of unmet need during the pandemic.\n- Subgroup_Did not experience symptoms - People reporting no mental health symptoms still show predictive power — possibly because they're less likely to report unmet need.\n\n- Subgroup_Male - Gender plays a role. This subgroup contributes to unmet need prediction — possibly indicating men are less/more likely to seek or need services.\n- Subgroup_70 - 79 years, 60 - 69 years, 50 - 59 years - Age continues to matter — each bracket contributes unique predictive value. The model picks up on patterns across generations.\n- Subgroup_Asian (NH)\t- Race/ethnicity plays a role — this group may have distinctive patterns of unmet need.\n- Subgroup_High school diploma or GED\t- Educational attainment is a strong predictor — likely tied to access, stigma, or insurance coverage.\n- Subgroup_Hawaii, Subgroup_North Dakota, Subgroup_New Jersey\tState-level context matters — either policy, availability, or culture is influencing unmet need across geography.\n- Subgroup_Without disability\tThe contrast between with/without disability may shape access or perceived need.\n\n\n\n","metadata":{}}]}